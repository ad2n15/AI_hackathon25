{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2a0aba5-fb39-48eb-8cc9-fbcd6beeef68",
   "metadata": {},
   "source": [
    "# **Challenge: Using LLMs to Structure Clinical Data**\n",
    "\n",
    "Please see Notebook 6_1 for information on setting up OntoGPT and ollama"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b93150-a198-4f25-bfc5-e0b1479ebe1f",
   "metadata": {},
   "source": [
    "# üß† Hackathon Challenge: Structuring Pathology Reports to Study Graft-versus-Host Disease (GvHD)\n",
    "\n",
    "## üß™ Scenario: A Pathologist‚Äôs Data Dilemma\n",
    "\n",
    "You are a **pathologist** working with a large collection of **free-text pathology reports from cancer patients who have undergone bone marrow transplantation**. These reports are rich with clinical insights but currently unstructured and difficult to analyze at scale.\n",
    "\n",
    "You are particularly interested in studying **Graft-versus-Host Disease (GvHD)** ‚Äî a serious and potentially life-threatening condition that occurs **when donor immune cells attack the recipient‚Äôs tissues**. This complication commonly arises after **allogeneic hematopoietic stem cell transplantation**, a treatment for patients with cancers such as leukemia, lymphoma, and myeloma.\n",
    "\n",
    "GvHD can affect multiple organs, especially the **skin, liver, and gastrointestinal (GI) tract**. Histopathological findings in reports often describe:\n",
    "\n",
    "- Apoptosis in epithelial layers  \n",
    "- Crypt destruction in the GI tract  \n",
    "- Interface dermatitis in the skin  \n",
    "- Bile duct injury in the liver  \n",
    "\n",
    "To better understand disease patterns, treatment outcomes, and potential genomic correlations, **you need structured data**.\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Your Mission\n",
    "\n",
    "Use **OntoGPT** and **Ollama** to **extract and structure information** from these free-text pathology reports into a machine-readable format.\n",
    "\n",
    "Your output should be:\n",
    "\n",
    "- One **`.txt` file per report**\n",
    "- In **YAML format**, as output by OntoGPT\n",
    "- With structured fields that capture relevant clinical, anatomical, and pathological findings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6520ccf-391c-480d-afbd-c68ddf30ed3e",
   "metadata": {},
   "source": [
    "## üõ†Ô∏è Tools & Hints\n",
    "\n",
    "### üß† Step 1: Pick Your Ollama Model\n",
    "\n",
    "Head to [Ollama's model search](https://ollama.com/search) and explore different LLMs.\n",
    "\n",
    "‚úÖ **Hint:**  \n",
    "Consider:\n",
    "- **Model size** (some larger models may be too slow or memory-intensive)\n",
    "- **Performance on biomedical or reasoning tasks**\n",
    "- **Instruction-following ability**  \n",
    "\n",
    "Pull them using:\n",
    "\n",
    "```bash\n",
    "ollama pull [model name]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c267b8f1-a2b0-44ee-9256-3b1e8da2f429",
   "metadata": {},
   "source": [
    "#### üöÄ Optional: Using a Fine-Tuned Model (Advanced)\n",
    "\n",
    "While **not required for this hackathon** (we are only using CPU resources), we want to highlight how **fine-tuning can improve performance** for this task.\n",
    "\n",
    "A **fine-tuned version of LLaMA 3.1 8B**, specifically trained to generate **accurate pathological statements from medical text**, is available here:\n",
    "\n",
    "üîó [UoS-HGIG/MIMIC on Hugging Face](https://huggingface.co/UoS-HGIG/MIMIC)\n",
    "\n",
    "This model has been fine-tuned on clinical data derived from MIMIC (open source medical records) and is tailored for tasks like extracting:\n",
    "\n",
    "- Pathology statements\n",
    "- Diagnostic phrases\n",
    "- Structured clinical observations\n",
    "\n",
    "You can download the fine-tuned weights and **merge them with the base LLaMA 3.1 8B model** to use it via your own infrastructure (GPU recommended).\n",
    "\n",
    "üß† **Reminder:** You do *not* need to use this model for the hackathon, but it's a great example of how domain-specific fine-tuning can boost performance in real-world biomedical NLP tasks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02dacac-424a-4cad-bd3c-31dfd13dcfb2",
   "metadata": {},
   "source": [
    "### üß¨ Step 2: Choose the Best OntoGPT Template\n",
    "\n",
    "Explore [OntoGPT templates](https://github.com/monarch-initiative/ontogpt/blob/main/src/ontogpt/templates).  \n",
    "These define the schema for what gets extracted.\n",
    "\n",
    "‚úÖ **Hint:**  \n",
    "Look for templates suitable for **histopathology**, **clinical reports**, or **disease findings**. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7c3e52-a504-4ffb-95cc-fd060c69ad12",
   "metadata": {},
   "source": [
    "### üß™ Step 3: Write a Script to Process the Reports\n",
    "\n",
    "Now that you‚Äôve selected your Ollama model and OntoGPT template, it‚Äôs time to **automate the processing**.\n",
    "\n",
    "üìù **Task:**\n",
    "Write a Python script that:\n",
    "\n",
    "1. Reads all `.txt` input files from the folder: `../CHIFIR_reports`\n",
    "2. Sends the content of each file to OntoGPT using your chosen template and model\n",
    "3. Saves the structured OntoGPT output as a new `.txt` file (in YAML format)  \n",
    "   ‚Äî use the same filename, but write it to a new folder (e.g., `structured_outputs/`)\n",
    "\n",
    "‚úÖ **Hint:**  \n",
    "OntoGPT has a CLI you can call from Python using `subprocess`. For example:\n",
    "\n",
    "```bash\n",
    "ontogpt extract -t histopathology -i input.txt -o output.yaml\n",
    "\n",
    "e.g.:\n",
    "import subprocess\n",
    "\n",
    "subprocess.run([\n",
    "    \"ontogpt\", \"extract\",\n",
    "    \"-t\", \"histopathology\",\n",
    "    \"-i\", \"path/to/input.txt\",\n",
    "    \"-o\", \"path/to/output.yaml\"\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b74deba-92f5-46e8-af1d-06af0569194b",
   "metadata": {},
   "source": [
    "## üèÜ How to Win\n",
    "\n",
    "The team that produces the **most accurate, complete, and well-structured outputs** from the pathology reports will be crowned the winner!\n",
    "\n",
    "### üß™ Judging Criteria:\n",
    "- üß† **Accuracy**: Are the key findings, anatomical sites, and diagnoses correctly extracted?\n",
    "- üßæ **Completeness**: Does the YAML output capture all relevant data from the report?\n",
    "\n",
    "üì¶ Bonus points for:\n",
    "- Comparative evaluation of different models\n",
    "\n",
    "Let the structuring begin ‚Äî may the cleanest YAML win! üí™\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
