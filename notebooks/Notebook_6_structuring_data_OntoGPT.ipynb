{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2a0aba5-fb39-48eb-8cc9-fbcd6beeef68",
   "metadata": {},
   "source": [
    "# **OntoGPT**\n",
    "OntoGPT is a Python package for extracting structured information from text with large language models (LLMs), instruction prompts, and ontology-based grounding. It works well with OpenAI's GPT models as well as a selection of other LLMs. OntoGPT's output can be used for general-purpose natural language tasks (e.g., named entity recognition and relation extraction), summarization, knowledge base and knowledge graph construction, and more.\n",
    "\n",
    "**Methods**\n",
    "The primary extraction method currently implemented in OntoGPT is SPIRES:\n",
    "\n",
    "SPIRES: Structured Prompt Interrogation and Recursive Extraction of Semantics\n",
    "A Zero-shot learning (ZSL) approach to extracting nested semantic structures from text\n",
    "This approach takes two inputs:1) LinkML schema  , 2) free text, and outputs knowledge in a structure conformant with the supplied schema in JSON, YAML, RDF or OWL formats\n",
    "\n",
    "**Uses OpenAI GPT models through their API, or one of a variety of LLMs on your local machine**\n",
    "\n",
    "You can run ollama server in the log in node as follwoing\n",
    "\n",
    "module load ollama  \n",
    "ollama serve  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e918f37-1579-4767-8f8c-b40e95b70362",
   "metadata": {},
   "source": [
    "* bind the local bin, where we installed OntoGPT to $PATH "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3cc458-0cfc-41e4-8d06-00b8087fe865",
   "metadata": {},
   "outputs": [],
   "source": [
    "%env PATH=../.local/bin:$PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ba5ae2-2088-4153-b75e-94b62dcdcffb",
   "metadata": {},
   "source": [
    "* test OntoGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3feec26-685a-4f8f-9d42-c19ada38819a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ontogpt extract --help"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a387b383-0cee-495b-bd5e-6705d6161119",
   "metadata": {},
   "source": [
    "* test OntoGPT with Ollama.gemma  \n",
    "Gemma is a family of lightweight, state-of-the-art open models built by Google DeepMind. Updated to version 1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30cc625-98a3-40ff-9029-1336d28aaba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ontogpt complete -m ollama/gemma:7b  \"Why did the squid cross the coral reef?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b93150-a198-4f25-bfc5-e0b1479ebe1f",
   "metadata": {},
   "source": [
    "* We can extract knowledge from the  text  into the GO pathway datamodel by running the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35740d11-88a1-4495-bc34-c1880e1468aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ontogpt extract -m ollama/gemma:7b -t gocam.GoCamAnnotations -i ../gocam-betacat.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828ea078-f719-4305-9e00-a3c29637675a",
   "metadata": {},
   "source": [
    "Note: The value accepted by the -t / --template argument is the base name of one of the LinkML schema / data model available to OntoGPT.  \n",
    "\n",
    "Use the command ontogpt list-templates to see all templates. Use the name in the first column with the --template option.  \n",
    "The output returned from the above command can be optionally redirected into an output file using the -o / --output.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e3e6ce-731f-4ef4-a010-eae6905d0372",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ontogpt extract -m ollama/gemma:7b -t drug -i ../gocam-betacat.txt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
