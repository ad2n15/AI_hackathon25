{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0385b7d-0af9-4274-bdfa-3c08acd64b3d",
   "metadata": {},
   "source": [
    "# What is Fine-Tuning?\n",
    "\n",
    "\n",
    "Fine-tuning is the process of taking a pretrained model (such as BERT, GPT, RoBERTa, or T5) and training it further on a specific task using a smaller, labeled dataset. Instead of training a model from scratch (which can take weeks and massive amounts of data), fine-tuning starts from a model that already understands the structure and meaning of language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b21b69dc-82ac-456e-8e8a-706e6495c6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helical.models.geneformer import GeneformerConfig, GeneformerFineTuningModel\n",
    "import anndata as ad\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b9baa5-8e35-496c-8a0d-9fe5eda2bd61",
   "metadata": {},
   "source": [
    "* Upload single cell data in annadata format\n",
    "* Define the labels column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c9f0d3dd-6ef0-4308-a33b-57f385263a11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AnnData object with n_obs × n_vars = 31680 × 37318\n",
      "    obs: 'component', 'stage', 'sex', 'sort.ids', 'fetal.ids', 'orig.dataset', 'sequencing.type', 'lanes', 'LVL1', 'LVL2', 'LVL3', 'LVL3_for_embryo_study'\n",
      "    var: 'n_cells'\n",
      "    obsm: 'X_umap'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ERYTHROID', 'LYMPHOID', 'MK', 'MYELOID', 'PROGENITOR', 'STROMA'}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data\n",
    "ann_data = ad.read_h5ad(\"../yolksac_human.h5ad\")\n",
    "print(ann_data)\n",
    "# Get the column for fine-tuning\n",
    "cell_types = list(ann_data.obs[\"LVL1\"][:1000])\n",
    "label_set = set(cell_types)\n",
    "label_set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4293a466-0568-413e-9d5e-ad3c65fb7296",
   "metadata": {},
   "source": [
    "* Define Geneformer configuration parameters\n",
    "\n",
    "\n",
    "- fine_tuning_head : Literal[\"classification\", \"regression\"] | HelicalBaseFineTuningHead\n",
    "\n",
    "- output_size : Optional[int]\n",
    "    The output size of the fine-tuning model. This is required if the `fine_tuning_head` is a string specified task. For a classification task this is number of unique classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bbadaa54-878b-4d1f-82e7-9dbbecef028c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a GeneformerConfig object\n",
    "\n",
    "geneformer_config = GeneformerConfig(model_name=\"gf-12L-95M-i4096\", batch_size=10, nproc = 32, accelerator = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b37c2f5-5d56-4d2e-9169-d8459182d6fd",
   "metadata": {},
   "source": [
    "Define the parameters required for Geneformer finetuning\n",
    "- fine_tuning_head : Literal[\"classification\", \"regression\"] | HelicalBaseFineTuningHead\n",
    "\n",
    "- output_size : Optional[int]\n",
    "    The output size of the fine-tuning model. This is required if the `fine_tuning_head` is a string specified task. For a classification task this is number of unique classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "954cd6f2-ee19-49c7-a630-e298ea5515ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:helical.models.geneformer.model:Model finished initializing.\n",
      "INFO:helical.models.geneformer.model:'gf-12L-95M-i4096' model is in 'eval' mode, on device 'cpu' with embedding mode 'cell'.\n"
     ]
    }
   ],
   "source": [
    "# Create a GeneformerFineTuningModel object\n",
    "geneformer_fine_tune = GeneformerFineTuningModel(geneformer_config=geneformer_config, fine_tuning_head=\"classification\", output_size=len(label_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a31de7-a3ca-43d9-9de6-b7a239317781",
   "metadata": {},
   "source": [
    "* Process the single cell data (map ensemble_ids and tokenization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1f4d77f0-325f-4e48-b9c5-845eeafa4f85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:helical.models.geneformer.model:Processing data for Geneformer.\n",
      "WARNING:py.warnings:/usr/local/lib/python3.11/site-packages/helical/models/base_models.py:88: ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual.\n",
      "  adata.var[\"index\"] = adata.var.index\n",
      "\n",
      "INFO:pyensembl.sequence_data:Loaded sequence dictionary from /scratch/aazd1f17/shared_space/AI_hackathon25/.cache/pyensembl/GRCh38/ensembl110/Homo_sapiens.GRCh38.cdna.all.fa.gz.pickle\n",
      "INFO:pyensembl.sequence_data:Loaded sequence dictionary from /scratch/aazd1f17/shared_space/AI_hackathon25/.cache/pyensembl/GRCh38/ensembl110/Homo_sapiens.GRCh38.ncrna.fa.gz.pickle\n",
      "INFO:pyensembl.sequence_data:Loaded sequence dictionary from /scratch/aazd1f17/shared_space/AI_hackathon25/.cache/pyensembl/GRCh38/ensembl110/Homo_sapiens.GRCh38.pep.all.fa.gz.pickle\n",
      "INFO:helical.utils.mapping:Mapped 21359 genes to Ensembl IDs from a total of 37318 genes.\n",
      "INFO:helical.models.geneformer.geneformer_tokenizer:AnnData object with n_obs × n_vars = 1000 × 37318\n",
      "    obs: 'component', 'stage', 'sex', 'sort.ids', 'fetal.ids', 'orig.dataset', 'sequencing.type', 'lanes', 'LVL1', 'LVL2', 'LVL3', 'LVL3_for_embryo_study', 'total_counts'\n",
      "    var: 'n_cells', 'index', 'ensembl_id', 'gene_ids_collapsed'\n",
      "    obsm: 'X_umap' has no column attribute 'filter_pass'; tokenizing all cells.\n",
      "INFO:helical.models.geneformer.geneformer_tokenizer:Creating dataset.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3c9f91a01704c58a80b6db190f71074",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=32):   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:helical.models.geneformer.model:Successfully processed the data for Geneformer.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'length', 'cell_types'],\n",
       "    num_rows: 1000\n",
       "})"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Process the data\n",
    "dataset = geneformer_fine_tune.process_data(ann_data[:1000])\n",
    "\n",
    "# Add column to the dataset\n",
    "dataset = dataset.add_column('cell_types', cell_types)\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ac0fcd-2725-44b2-b192-4adff211d0d2",
   "metadata": {},
   "source": [
    "* convert text labels (cell type names) into numeric class IDs, which is a common preprocessing step when preparing data for machine learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "94231353-56cb-4e30-a7b8-3dcb9571351f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac6baaa356984e68be8f2966733c8ee3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes in the dataset: 6\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionary to map cell types to ids\n",
    "class_id_dict = dict(zip(label_set, [i for i in range(len(label_set))]))\n",
    "\n",
    "def classes_to_ids(example):\n",
    "    example[\"cell_types\"] = class_id_dict[example[\"cell_types\"]]\n",
    "    return example\n",
    "\n",
    "# Convert cell types to ids\n",
    "dataset = dataset.map(classes_to_ids, num_proc=1)\n",
    "\n",
    "class_id_dict\n",
    "\n",
    "# Check the unique values in the \"cell_types\" column to find the number of classes\n",
    "num_classes = len(set(dataset[\"cell_types\"]))  # Or use np.unique() if you're working with NumPy arrays\n",
    "\n",
    "print(f\"Number of classes in the dataset: {num_classes}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bbb7eda0-9116-426b-bae7-250f7e77aa01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:helical.models.geneformer.geneformer_utils:CLS token present in token dictionary, excluding from average.\n",
      "WARNING:helical.models.geneformer.geneformer_utils:EOS token present in token dictionary, excluding from average.\n",
      "INFO:helical.models.geneformer.fine_tuning_model:Freezing the first 2 encoder layers of the Geneformer model during fine-tuning.\n",
      "INFO:helical.models.geneformer.fine_tuning_model:Starting Fine-Tuning\n",
      "Fine-Tuning: epoch 1/1: 100%|█████| 100/100 [22:31<00:00, 13.51s/it, loss=0.309]\n",
      "INFO:helical.models.geneformer.fine_tuning_model:Fine-Tuning Complete. Epochs: 1\n"
     ]
    }
   ],
   "source": [
    "# Fine-tune the model\n",
    "geneformer_fine_tune.train(train_dataset=dataset, label=\"cell_types\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "baee9a00-b35e-4779-a07a-c3401bb5938b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the fine-tuned model to a specified directory\n",
    "import torch\n",
    "\n",
    "# Save the model's state_dict (weights)\n",
    "torch.save(geneformer_fine_tune.state_dict(), './fine_tuned_geneformer.pth')\n",
    "\n",
    "import pickle\n",
    "\n",
    "# Save the configuration (such as model architecture, hyperparameters)\n",
    "with open('./fine_tuned_geneformer_config.pkl', 'wb') as f:\n",
    "    pickle.dump(geneformer_config, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e2795a-b5d5-444f-ba9c-53f3824a39b0",
   "metadata": {},
   "source": [
    "* Outputs: These are typically the logits from the final classification layer of the model.\n",
    "\n",
    "shape = number of cells x number of classes\n",
    "\n",
    "Embeddings: These are dense vector representations of the input\n",
    "shape = number of cells x number of dimensions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dced79e8-c656-4432-84d0-0551eba1ef29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:helical.models.geneformer.geneformer_utils:CLS token present in token dictionary, excluding from average.\n",
      "WARNING:helical.models.geneformer.geneformer_utils:EOS token present in token dictionary, excluding from average.\n",
      "Generating Outputs: 100%|███████████████████████| 10/10 [00:40<00:00,  4.02s/it]\n",
      "INFO:helical.models.geneformer.model:Started getting embeddings:\n",
      "WARNING:helical.models.geneformer.geneformer_utils:CLS token present in token dictionary, excluding from average.\n",
      "WARNING:helical.models.geneformer.geneformer_utils:EOS token present in token dictionary, excluding from average.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d24c56cadb694cf7815e1983b1ab57c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:helical.models.geneformer.model:Finished getting embeddings.\n"
     ]
    }
   ],
   "source": [
    "# Get logits from the fine-tuned model\n",
    "outputs = geneformer_fine_tune.get_outputs(dataset)\n",
    "#print(outputs[:100])\n",
    "\n",
    "# Get embeddings from the fine-tuned model\n",
    "embeddings = geneformer_fine_tune.get_embeddings(dataset)\n",
    "#print(embeddings[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bb368d4d-0e91-4496-affb-03930616d0d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs shape: (100, 4)\n",
      "Embeddings shape: (100, 512)\n"
     ]
    }
   ],
   "source": [
    "# Print dimensions of model outputs (logits)\n",
    "print(\"Outputs shape:\", outputs.shape)\n",
    "\n",
    "# Print dimensions of embeddings\n",
    "print(\"Embeddings shape:\", embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "03238297-13e9-4c8e-a0b9-be43ee3c5d27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:helical.models.geneformer.model:Model finished initializing.\n",
      "INFO:helical.models.geneformer.model:'gf-12L-95M-i4096' model is in 'eval' mode, on device 'cpu' with embedding mode 'cell'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the model configuration\n",
    "with open('./fine_tuned_geneformer_config.pkl', 'rb') as f:\n",
    "    loaded_config = pickle.load(f)\n",
    "\n",
    "# Recreate the model using the configuration\n",
    "geneformer_fine_tune = GeneformerFineTuningModel(geneformer_config=loaded_config, fine_tuning_head=\"classification\", output_size=len(label_set))\n",
    "\n",
    "# Load the saved weights\n",
    "geneformer_fine_tune.load_state_dict(torch.load('./fine_tuned_geneformer.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "96bba31b-c301-4c44-84bc-2f25738b07dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:helical.models.geneformer.model:Processing data for Geneformer.\n",
      "WARNING:py.warnings:/usr/local/lib/python3.11/site-packages/helical/models/base_models.py:88: ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual.\n",
      "  adata.var[\"index\"] = adata.var.index\n",
      "\n",
      "INFO:pyensembl.sequence_data:Loaded sequence dictionary from /scratch/aazd1f17/shared_space/AI_hackathon25/.cache/pyensembl/GRCh38/ensembl110/Homo_sapiens.GRCh38.cdna.all.fa.gz.pickle\n",
      "INFO:pyensembl.sequence_data:Loaded sequence dictionary from /scratch/aazd1f17/shared_space/AI_hackathon25/.cache/pyensembl/GRCh38/ensembl110/Homo_sapiens.GRCh38.ncrna.fa.gz.pickle\n",
      "INFO:pyensembl.sequence_data:Loaded sequence dictionary from /scratch/aazd1f17/shared_space/AI_hackathon25/.cache/pyensembl/GRCh38/ensembl110/Homo_sapiens.GRCh38.pep.all.fa.gz.pickle\n",
      "INFO:helical.utils.mapping:Mapped 21359 genes to Ensembl IDs from a total of 37318 genes.\n",
      "INFO:helical.models.geneformer.geneformer_tokenizer:AnnData object with n_obs × n_vars = 10 × 37318\n",
      "    obs: 'component', 'stage', 'sex', 'sort.ids', 'fetal.ids', 'orig.dataset', 'sequencing.type', 'lanes', 'LVL1', 'LVL2', 'LVL3', 'LVL3_for_embryo_study', 'total_counts'\n",
      "    var: 'n_cells', 'index', 'ensembl_id', 'gene_ids_collapsed'\n",
      "    obsm: 'X_umap' has no column attribute 'filter_pass'; tokenizing all cells.\n",
      "INFO:helical.models.geneformer.geneformer_tokenizer:Creating dataset.\n",
      "num_proc must be <= 10. Reducing num_proc to 10 for dataset of size 10.\n",
      "WARNING:datasets.arrow_dataset:num_proc must be <= 10. Reducing num_proc to 10 for dataset of size 10.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fec862f9ad54687b08b5691379eaa89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=10):   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:helical.models.geneformer.model:Successfully processed the data for Geneformer.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bea43e6a1bb464d8f6dc812ea8e4460",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the data\n",
    "ann_data = ad.read_h5ad(\"../yolksac_human.h5ad\")\n",
    "\n",
    "# Get the column for fine-tuning\n",
    "cell_types = list(ann_data.obs[\"LVL1\"][:10])\n",
    "label_set = set(cell_types)\n",
    "label_set\n",
    "# Process the data\n",
    "dataset = geneformer_fine_tune.process_data(ann_data[:10])\n",
    "\n",
    "dataset = dataset.add_column('cell_types', cell_types)\n",
    "\n",
    "# Create a dictionary to map cell types to ids\n",
    "class_id_dict = dict(zip(label_set, [i for i in range(len(label_set))]))\n",
    "\n",
    "def classes_to_ids(example):\n",
    "    example[\"cell_types\"] = class_id_dict[example[\"cell_types\"]]\n",
    "    return example\n",
    "\n",
    "# Convert cell types to ids\n",
    "dataset = dataset.map(classes_to_ids, num_proc=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1f452b39-02b6-4c5a-b5b0-10f78173a0ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:helical.models.geneformer.geneformer_utils:CLS token present in token dictionary, excluding from average.\n",
      "WARNING:helical.models.geneformer.geneformer_utils:EOS token present in token dictionary, excluding from average.\n",
      "Generating Outputs: 100%|█████████████████████████| 1/1 [00:06<00:00,  6.33s/it]\n"
     ]
    }
   ],
   "source": [
    "# Get logits from the fine-tuned model\n",
    "outputs = geneformer_fine_tune.get_outputs(dataset)\n",
    "#print(outputs[:10])\n",
    "\n",
    "# Get embeddings from the fine-tuned model\n",
    "#embeddings = geneformer_fine_tune.get_embeddings(dataset)\n",
    "#print(embeddings[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f718b88b-4606-4e89-89aa-4e69705fd5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Convert logits to probabilities using softmax\n",
    "probs = torch.nn.functional.softmax(torch.tensor(outputs), dim=-1)\n",
    "#probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "89a4b939-5b0d-4dae-92b6-a76c70989605",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, 1, 1, 5, 5, 5, 2, 5])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get predicted class (the class with the highest probability)\n",
    "predicted_classes = probs.argmax(dim=-1).numpy()  # Convert to numpy for easier handling\n",
    "predicted_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "60a9b469-8973-450b-9908-f6da9f8a1f3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 0, 0, 2, 2, 2, 1, 2])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# True labels (cell types from dataset)\n",
    "true_labels = np.array(dataset[\"cell_types\"])\n",
    "true_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1aadcf1c-3b57-4a7d-b3e2-cca395e2917f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.00%\n"
     ]
    }
   ],
   "source": [
    "# Compare predicted labels with true labels to calculate accuracy\n",
    "accuracy = (predicted_classes == true_labels).mean()\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172cc62d-7066-4cac-9ed0-bab80835cba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
