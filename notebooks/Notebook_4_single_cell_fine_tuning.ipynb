{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0385b7d-0af9-4274-bdfa-3c08acd64b3d",
   "metadata": {},
   "source": [
    "# What is Fine-Tuning?\n",
    "\n",
    "\n",
    "Fine-tuning is the process of taking a pretrained model and training it further on a specific task using a smaller, labeled dataset. Instead of training a model from scratch (which can take weeks and massive amounts of data), fine-tuning starts from a model that already understands the structure and meaning of language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b21b69dc-82ac-456e-8e8a-706e6495c6a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:datasets:PyTorch version 2.6.0 available.\n"
     ]
    }
   ],
   "source": [
    "from helical.models.geneformer import GeneformerConfig, GeneformerFineTuningModel\n",
    "import anndata as ad\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b9baa5-8e35-496c-8a0d-9fe5eda2bd61",
   "metadata": {},
   "source": [
    "* Upload single cell data in annadata format\n",
    "* Define the labels column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9f0d3dd-6ef0-4308-a33b-57f385263a11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AnnData object with n_obs × n_vars = 31680 × 37318\n",
      "    obs: 'component', 'stage', 'sex', 'sort.ids', 'fetal.ids', 'orig.dataset', 'sequencing.type', 'lanes', 'LVL1', 'LVL2', 'LVL3', 'LVL3_for_embryo_study'\n",
      "    var: 'n_cells'\n",
      "    obsm: 'X_umap'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ERYTHROID', 'MYELOID', 'STROMA'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data\n",
    "ann_data = ad.read_h5ad(\"../yolksac_human.h5ad\")\n",
    "print(ann_data)\n",
    "# Get the column for fine-tuning\n",
    "cell_types = list(ann_data.obs[\"LVL1\"][:10])\n",
    "label_set = set(cell_types)\n",
    "label_set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4293a466-0568-413e-9d5e-ad3c65fb7296",
   "metadata": {},
   "source": [
    "* Define Geneformer configuration parameters\n",
    "\n",
    "\n",
    "- fine_tuning_head : Literal[\"classification\", \"regression\"] | HelicalBaseFineTuningHead\n",
    "\n",
    "- output_size : Optional[int]\n",
    "    The output size of the fine-tuning model. This is required if the `fine_tuning_head` is a string specified task. For a classification task this is number of unique classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbadaa54-878b-4d1f-82e7-9dbbecef028c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a GeneformerConfig object\n",
    "\n",
    "geneformer_config = GeneformerConfig(model_name=\"gf-12L-95M-i4096\", batch_size=10, nproc = 32, accelerator = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b37c2f5-5d56-4d2e-9169-d8459182d6fd",
   "metadata": {},
   "source": [
    "Define the parameters required for Geneformer finetuning\n",
    "- fine_tuning_head : Literal[\"classification\", \"regression\"] | HelicalBaseFineTuningHead\n",
    "\n",
    "- output_size : Optional[int]\n",
    "    The output size of the fine-tuning model. This is required if the `fine_tuning_head` is a string specified task. For a classification task this is number of unique classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "954cd6f2-ee19-49c7-a630-e298ea5515ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:helical.models.geneformer.model:Model finished initializing.\n",
      "INFO:helical.models.geneformer.model:'gf-12L-95M-i4096' model is in 'eval' mode, on device 'cpu' with embedding mode 'cell'.\n"
     ]
    }
   ],
   "source": [
    "# Create a GeneformerFineTuningModel object\n",
    "geneformer_fine_tune = GeneformerFineTuningModel(geneformer_config=geneformer_config, fine_tuning_head=\"classification\", output_size=len(label_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a31de7-a3ca-43d9-9de6-b7a239317781",
   "metadata": {},
   "source": [
    "* Process the single cell data (map ensemble_ids and tokenization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f4d77f0-325f-4e48-b9c5-845eeafa4f85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:helical.models.geneformer.model:Processing data for Geneformer.\n",
      "WARNING:py.warnings:/usr/local/lib/python3.11/site-packages/helical/models/base_models.py:88: ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual.\n",
      "  adata.var[\"index\"] = adata.var.index\n",
      "\n",
      "INFO:pyensembl.sequence_data:Loaded sequence dictionary from /scratch/aazd1f17/shared_space/AI_hackathon25/.cache/pyensembl/GRCh38/ensembl110/Homo_sapiens.GRCh38.cdna.all.fa.gz.pickle\n",
      "INFO:pyensembl.sequence_data:Loaded sequence dictionary from /scratch/aazd1f17/shared_space/AI_hackathon25/.cache/pyensembl/GRCh38/ensembl110/Homo_sapiens.GRCh38.ncrna.fa.gz.pickle\n",
      "INFO:pyensembl.sequence_data:Loaded sequence dictionary from /scratch/aazd1f17/shared_space/AI_hackathon25/.cache/pyensembl/GRCh38/ensembl110/Homo_sapiens.GRCh38.pep.all.fa.gz.pickle\n",
      "INFO:helical.utils.mapping:Mapped 21359 genes to Ensembl IDs from a total of 37318 genes.\n",
      "INFO:helical.models.geneformer.geneformer_tokenizer:AnnData object with n_obs × n_vars = 10 × 37318\n",
      "    obs: 'component', 'stage', 'sex', 'sort.ids', 'fetal.ids', 'orig.dataset', 'sequencing.type', 'lanes', 'LVL1', 'LVL2', 'LVL3', 'LVL3_for_embryo_study', 'total_counts'\n",
      "    var: 'n_cells', 'index', 'ensembl_id', 'gene_ids_collapsed'\n",
      "    obsm: 'X_umap' has no column attribute 'filter_pass'; tokenizing all cells.\n",
      "INFO:helical.models.geneformer.geneformer_tokenizer:Creating dataset.\n",
      "num_proc must be <= 10. Reducing num_proc to 10 for dataset of size 10.\n",
      "WARNING:datasets.arrow_dataset:num_proc must be <= 10. Reducing num_proc to 10 for dataset of size 10.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65ab56ba3b0844deab1b112ea6a90604",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=10):   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:helical.models.geneformer.model:Successfully processed the data for Geneformer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['input_ids', 'length'],\n",
      "    num_rows: 10\n",
      "})\n",
      "Dataset({\n",
      "    features: ['input_ids', 'length', 'cell_types'],\n",
      "    num_rows: 10\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Process the data\n",
    "dataset = geneformer_fine_tune.process_data(ann_data[:10])\n",
    "\n",
    "print(dataset)\n",
    "# Add column to the dataset\n",
    "dataset2 = dataset.add_column('cell_types', cell_types)\n",
    "\n",
    "print(dataset2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ac0fcd-2725-44b2-b192-4adff211d0d2",
   "metadata": {},
   "source": [
    "* convert text labels (cell type names) into numeric class IDs, which is a common preprocessing step when preparing data for machine learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94231353-56cb-4e30-a7b8-3dcb9571351f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'MYELOID': 0, 'ERYTHROID': 1, 'STROMA': 2}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcb3dda75d2a4510a576a4560743ff6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes in the dataset: 3\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionary to map cell types to ids\n",
    "class_id_dict = dict(zip(label_set, [i for i in range(len(label_set))]))\n",
    "print(class_id_dict)\n",
    "\n",
    "def classes_to_ids(example):\n",
    "    example[\"cell_types\"] = class_id_dict[example[\"cell_types\"]]\n",
    "    return example\n",
    "\n",
    "# Convert cell types to ids\n",
    "dataset2 = dataset2.map(classes_to_ids, num_proc=1)\n",
    "\n",
    "\n",
    "# Check the unique values in the \"cell_types\" column to find the number of classes\n",
    "num_classes = len(set(dataset2[\"cell_types\"]))  # Or use np.unique() if you're working with NumPy arrays\n",
    "\n",
    "print(f\"Number of classes in the dataset: {num_classes}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd37cff0-a64e-4ec7-87c4-2c5966df13c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:helical.models.geneformer.geneformer_utils:CLS token present in token dictionary, excluding from average.\n",
      "WARNING:helical.models.geneformer.geneformer_utils:EOS token present in token dictionary, excluding from average.\n",
      "INFO:helical.models.geneformer.fine_tuning_model:Freezing the first 2 encoder layers of the Geneformer model during fine-tuning.\n",
      "INFO:helical.models.geneformer.fine_tuning_model:Starting Fine-Tuning\n",
      "Fine-Tuning: epoch 1/2: 100%|██████████| 1/1 [00:22<00:00, 22.30s/it, loss=1.11]\n",
      "Fine-Tuning: epoch 2/2: 100%|██████████| 1/1 [00:19<00:00, 19.01s/it, loss=0.97]\n",
      "INFO:helical.models.geneformer.fine_tuning_model:Fine-Tuning Complete. Epochs: 2\n"
     ]
    }
   ],
   "source": [
    "# Fine-tune the model\n",
    "geneformer_fine_tune.train(train_dataset=dataset2, label=\"cell_types\", epochs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36650ca6-f749-4ed6-8271-47d03ea3a2f9",
   "metadata": {},
   "source": [
    "\n",
    "# Saving only the model weights (state_dict)\n",
    "torch.save(geneformer_fine_tune.state_dict(), './fine_tuned_geneformer.pth')\n",
    "\n",
    "# Saving the model configuration\n",
    "import pickle\n",
    "with open('./fine_tuned_geneformer_config.pkl', 'wb') as f:\n",
    "    pickle.dump(geneformer_config, f)\n",
    "\n",
    "# Or Saving the full model (architecture + weights)\n",
    "torch.save(geneformer_fine_tune, './full_geneformer_model.pth')\n",
    "\n",
    "# Loading the full model (architecture + weights)\n",
    "loaded_model = torch.load('./full_geneformer_model.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "baee9a00-b35e-4779-a07a-c3401bb5938b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the fine-tuned model to a specified directory\n",
    "\n",
    "import torch\n",
    "# Save the model's state_dict (weights)\n",
    "torch.save(geneformer_fine_tune.state_dict(), './fine_tuned_geneformer.pth')\n",
    "\n",
    "import pickle\n",
    "\n",
    "# Save the configuration (such as model architecture, hyperparameters)\n",
    "with open('./fine_tuned_geneformer_config.pkl', 'wb') as f:\n",
    "    pickle.dump(geneformer_config, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e2795a-b5d5-444f-ba9c-53f3824a39b0",
   "metadata": {},
   "source": [
    "* Outputs: These are typically the logits from the final classification layer of the model.\n",
    "\n",
    "shape = number of cells x number of classes\n",
    "\n",
    "Embeddings: These are dense vector representations of the input\n",
    "shape = number of cells x number of dimensions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dced79e8-c656-4432-84d0-0551eba1ef29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:helical.models.geneformer.geneformer_utils:CLS token present in token dictionary, excluding from average.\n",
      "WARNING:helical.models.geneformer.geneformer_utils:EOS token present in token dictionary, excluding from average.\n",
      "Generating Outputs: 100%|█████████████████████████| 1/1 [00:07<00:00,  7.46s/it]\n",
      "INFO:helical.models.geneformer.model:Started getting embeddings:\n",
      "WARNING:helical.models.geneformer.geneformer_utils:CLS token present in token dictionary, excluding from average.\n",
      "WARNING:helical.models.geneformer.geneformer_utils:EOS token present in token dictionary, excluding from average.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5237a3405a14759ae781489a88d1144",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:helical.models.geneformer.model:Finished getting embeddings.\n"
     ]
    }
   ],
   "source": [
    "# Get logits from the fine-tuned model\n",
    "outputs = geneformer_fine_tune.get_outputs(dataset)\n",
    "#print(outputs[:100])\n",
    "\n",
    "# Get embeddings from the fine-tuned model\n",
    "embeddings = geneformer_fine_tune.get_embeddings(dataset)\n",
    "#print(embeddings[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bb368d4d-0e91-4496-affb-03930616d0d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs shape: (10, 3)\n",
      "Embeddings shape: (10, 512)\n"
     ]
    }
   ],
   "source": [
    "# Print dimensions of model outputs (logits)\n",
    "print(\"Outputs shape:\", outputs.shape)\n",
    "\n",
    "# Print dimensions of embeddings\n",
    "print(\"Embeddings shape:\", embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "03238297-13e9-4c8e-a0b9-be43ee3c5d27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:helical.models.geneformer.model:Model finished initializing.\n",
      "INFO:helical.models.geneformer.model:'gf-12L-95M-i4096' model is in 'eval' mode, on device 'cpu' with embedding mode 'cell'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the model configuration\n",
    "with open('./fine_tuned_geneformer_config.pkl', 'rb') as f:\n",
    "    loaded_config = pickle.load(f)\n",
    "\n",
    "# Recreate the model using the configuration\n",
    "geneformer_fine_tune = GeneformerFineTuningModel(geneformer_config=loaded_config, fine_tuning_head=\"classification\", output_size=len(label_set))\n",
    "\n",
    "# Load the saved weights\n",
    "geneformer_fine_tune.load_state_dict(torch.load('./fine_tuned_geneformer.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "96bba31b-c301-4c44-84bc-2f25738b07dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:helical.models.geneformer.model:Processing data for Geneformer.\n",
      "WARNING:py.warnings:/usr/local/lib/python3.11/site-packages/helical/models/base_models.py:88: ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual.\n",
      "  adata.var[\"index\"] = adata.var.index\n",
      "\n",
      "INFO:pyensembl.sequence_data:Loaded sequence dictionary from /scratch/aazd1f17/shared_space/AI_hackathon25/.cache/pyensembl/GRCh38/ensembl110/Homo_sapiens.GRCh38.cdna.all.fa.gz.pickle\n",
      "INFO:pyensembl.sequence_data:Loaded sequence dictionary from /scratch/aazd1f17/shared_space/AI_hackathon25/.cache/pyensembl/GRCh38/ensembl110/Homo_sapiens.GRCh38.ncrna.fa.gz.pickle\n",
      "INFO:pyensembl.sequence_data:Loaded sequence dictionary from /scratch/aazd1f17/shared_space/AI_hackathon25/.cache/pyensembl/GRCh38/ensembl110/Homo_sapiens.GRCh38.pep.all.fa.gz.pickle\n",
      "INFO:helical.utils.mapping:Mapped 21359 genes to Ensembl IDs from a total of 37318 genes.\n",
      "INFO:helical.models.geneformer.geneformer_tokenizer:AnnData object with n_obs × n_vars = 10 × 37318\n",
      "    obs: 'component', 'stage', 'sex', 'sort.ids', 'fetal.ids', 'orig.dataset', 'sequencing.type', 'lanes', 'LVL1', 'LVL2', 'LVL3', 'LVL3_for_embryo_study', 'total_counts'\n",
      "    var: 'n_cells', 'index', 'ensembl_id', 'gene_ids_collapsed'\n",
      "    obsm: 'X_umap' has no column attribute 'filter_pass'; tokenizing all cells.\n",
      "INFO:helical.models.geneformer.geneformer_tokenizer:Creating dataset.\n",
      "num_proc must be <= 10. Reducing num_proc to 10 for dataset of size 10.\n",
      "WARNING:datasets.arrow_dataset:num_proc must be <= 10. Reducing num_proc to 10 for dataset of size 10.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfe65ffb720745f8a0019ea1e0650125",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=10):   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:helical.models.geneformer.model:Successfully processed the data for Geneformer.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b94aa03869174757891ac2f103cb1509",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the data\n",
    "ann_data = ad.read_h5ad(\"../yolksac_human.h5ad\")\n",
    "\n",
    "# Get the column for fine-tuning\n",
    "cell_types = list(ann_data.obs[\"LVL1\"][:10])\n",
    "label_set = set(cell_types)\n",
    "label_set\n",
    "# Process the data\n",
    "dataset = geneformer_fine_tune.process_data(ann_data[:10])\n",
    "\n",
    "dataset = dataset.add_column('cell_types', cell_types)\n",
    "\n",
    "# Create a dictionary to map cell types to ids\n",
    "class_id_dict = dict(zip(label_set, [i for i in range(len(label_set))]))\n",
    "\n",
    "def classes_to_ids(example):\n",
    "    example[\"cell_types\"] = class_id_dict[example[\"cell_types\"]]\n",
    "    return example\n",
    "\n",
    "# Convert cell types to ids\n",
    "dataset = dataset.map(classes_to_ids, num_proc=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1f452b39-02b6-4c5a-b5b0-10f78173a0ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:helical.models.geneformer.geneformer_utils:CLS token present in token dictionary, excluding from average.\n",
      "WARNING:helical.models.geneformer.geneformer_utils:EOS token present in token dictionary, excluding from average.\n",
      "Generating Outputs: 100%|█████████████████████████| 1/1 [00:07<00:00,  7.07s/it]\n",
      "INFO:helical.models.geneformer.model:Started getting embeddings:\n",
      "WARNING:helical.models.geneformer.geneformer_utils:CLS token present in token dictionary, excluding from average.\n",
      "WARNING:helical.models.geneformer.geneformer_utils:EOS token present in token dictionary, excluding from average.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.33764753 -0.63448006  0.42256805]\n",
      " [-0.0047673  -0.31886572  0.3476621 ]\n",
      " [ 0.4034266  -0.47087127  0.47804916]\n",
      " [-0.28821072 -0.18367608  0.20982245]\n",
      " [-0.03870388 -0.30438682  0.35442135]\n",
      " [ 0.6792635  -0.4365916   0.19478877]\n",
      " [ 0.6383105  -0.34320307  0.34863678]\n",
      " [ 0.48446694 -0.51842535  0.12969084]\n",
      " [ 0.10496124 -0.5309649   0.45663705]\n",
      " [ 0.6005198  -0.40026966  0.1865585 ]]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a535d3d183bb4b969d1bbdd26c78f435",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:helical.models.geneformer.model:Finished getting embeddings.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.03350314  0.13316047  0.20343904 ...  0.8142347  -0.3028932\n",
      "   0.08662338]\n",
      " [ 0.02586686  0.08685685  0.10706159 ...  0.508063   -0.20464893\n",
      "  -0.00271893]\n",
      " [ 0.0270964   0.09861639  0.18019074 ...  0.5467254  -0.32423416\n",
      "   0.11923523]\n",
      " ...\n",
      " [-0.01033951  0.01030621  0.08626219 ...  0.47623956 -0.1535618\n",
      "  -0.10797301]\n",
      " [-0.0342384   0.06156068  0.12234074 ...  0.41991723 -0.19008005\n",
      "   0.0402521 ]\n",
      " [ 0.02662977  0.10814787  0.21575229 ...  0.5291545  -0.3622686\n",
      "   0.05420014]]\n"
     ]
    }
   ],
   "source": [
    "# Get logits from the fine-tuned model\n",
    "outputs = geneformer_fine_tune.get_outputs(dataset)\n",
    "print(outputs[:10])\n",
    "\n",
    "# Get embeddings from the fine-tuned model\n",
    "embeddings = geneformer_fine_tune.get_embeddings(dataset)\n",
    "print(embeddings[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f718b88b-4606-4e89-89aa-4e69705fd5da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4054, 0.1533, 0.4413],\n",
      "        [0.3172, 0.2317, 0.4512],\n",
      "        [0.4009, 0.1672, 0.4319],\n",
      "        [0.2663, 0.2956, 0.4381],\n",
      "        [0.3079, 0.2360, 0.4561],\n",
      "        [0.5145, 0.1686, 0.3169],\n",
      "        [0.4710, 0.1765, 0.3525],\n",
      "        [0.4835, 0.1774, 0.3391],\n",
      "        [0.3389, 0.1794, 0.4817],\n",
      "        [0.4929, 0.1812, 0.3259]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Convert logits to probabilities using softmax\n",
    "probs = torch.nn.functional.softmax(torch.tensor(outputs), dim=-1)\n",
    "print(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "89a4b939-5b0d-4dae-92b6-a76c70989605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 2 2 2 0 0 0 2 0]\n"
     ]
    }
   ],
   "source": [
    "# Get predicted class (the class with the highest probability)\n",
    "predicted_classes = probs.argmax(dim=-1).numpy()  # Convert to numpy for easier handling\n",
    "print(predicted_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "60a9b469-8973-450b-9908-f6da9f8a1f3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 2 1 1 0 0 0 2 0]\n"
     ]
    }
   ],
   "source": [
    "# True labels (cell types from dataset)\n",
    "true_labels = np.array(dataset[\"cell_types\"])\n",
    "print(true_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1aadcf1c-3b57-4a7d-b3e2-cca395e2917f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 80.00%\n"
     ]
    }
   ],
   "source": [
    "# Compare predicted labels with true labels to calculate accuracy\n",
    "accuracy = (predicted_classes == true_labels).mean()\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172cc62d-7066-4cac-9ed0-bab80835cba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
