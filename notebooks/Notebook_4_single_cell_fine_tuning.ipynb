{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0385b7d-0af9-4274-bdfa-3c08acd64b3d",
   "metadata": {},
   "source": [
    "# What is Fine-Tuning?\n",
    "\n",
    "\n",
    "Fine-tuning is the process of taking a pretrained model and training it further on a specific task using a smaller, labeled dataset. Instead of training a model from scratch (which can take weeks and massive amounts of data), fine-tuning starts from a model that already understands the structure and meaning of language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21b69dc-82ac-456e-8e8a-706e6495c6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helical.models.geneformer import GeneformerConfig, GeneformerFineTuningModel\n",
    "import anndata as ad\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b9baa5-8e35-496c-8a0d-9fe5eda2bd61",
   "metadata": {},
   "source": [
    "* Upload single cell data in annadata format\n",
    "* Define the labels column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f0d3dd-6ef0-4308-a33b-57f385263a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "ann_data = ad.read_h5ad(\"../yolksac_human.h5ad\")\n",
    "print(ann_data)\n",
    "# Get the column for fine-tuning\n",
    "cell_types = list(ann_data.obs[\"LVL1\"][:10])\n",
    "label_set = set(cell_types)\n",
    "label_set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4293a466-0568-413e-9d5e-ad3c65fb7296",
   "metadata": {},
   "source": [
    "* Define Geneformer configuration parameters\n",
    "\n",
    "\n",
    "- fine_tuning_head : Literal[\"classification\", \"regression\"] | HelicalBaseFineTuningHead\n",
    "\n",
    "- output_size : Optional[int]\n",
    "    The output size of the fine-tuning model. This is required if the `fine_tuning_head` is a string specified task. For a classification task this is number of unique classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbadaa54-878b-4d1f-82e7-9dbbecef028c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a GeneformerConfig object\n",
    "\n",
    "geneformer_config = GeneformerConfig(model_name=\"gf-12L-95M-i4096\", batch_size=10, nproc = 32, accelerator = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b37c2f5-5d56-4d2e-9169-d8459182d6fd",
   "metadata": {},
   "source": [
    "Define the parameters required for Geneformer finetuning\n",
    "- fine_tuning_head : Literal[\"classification\", \"regression\"] | HelicalBaseFineTuningHead\n",
    "\n",
    "- output_size : Optional[int]\n",
    "    The output size of the fine-tuning model. This is required if the `fine_tuning_head` is a string specified task. For a classification task this is number of unique classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954cd6f2-ee19-49c7-a630-e298ea5515ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a GeneformerFineTuningModel object\n",
    "geneformer_fine_tune = GeneformerFineTuningModel(geneformer_config=geneformer_config, fine_tuning_head=\"classification\", output_size=len(label_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a31de7-a3ca-43d9-9de6-b7a239317781",
   "metadata": {},
   "source": [
    "* Process the single cell data (map ensemble_ids and tokenization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4d77f0-325f-4e48-b9c5-845eeafa4f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the data\n",
    "dataset = geneformer_fine_tune.process_data(ann_data[:10])\n",
    "\n",
    "print(dataset)\n",
    "# Add column to the dataset\n",
    "dataset2 = dataset.add_column('cell_types', cell_types)\n",
    "\n",
    "print(dataset2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ac0fcd-2725-44b2-b192-4adff211d0d2",
   "metadata": {},
   "source": [
    "* convert text labels (cell type names) into numeric class IDs, which is a common preprocessing step when preparing data for machine learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94231353-56cb-4e30-a7b8-3dcb9571351f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to map cell types to ids\n",
    "class_id_dict = dict(zip(label_set, [i for i in range(len(label_set))]))\n",
    "print(class_id_dict)\n",
    "\n",
    "def classes_to_ids(example):\n",
    "    example[\"cell_types\"] = class_id_dict[example[\"cell_types\"]]\n",
    "    return example\n",
    "\n",
    "# Convert cell types to ids\n",
    "dataset2 = dataset2.map(classes_to_ids, num_proc=1)\n",
    "\n",
    "\n",
    "# Check the unique values in the \"cell_types\" column to find the number of classes\n",
    "num_classes = len(set(dataset2[\"cell_types\"]))  # Or use np.unique() if you're working with NumPy arrays\n",
    "\n",
    "print(f\"Number of classes in the dataset: {num_classes}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd37cff0-a64e-4ec7-87c4-2c5966df13c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tune the model\n",
    "geneformer_fine_tune.train(train_dataset=dataset2, label=\"cell_types\", epochs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36650ca6-f749-4ed6-8271-47d03ea3a2f9",
   "metadata": {},
   "source": [
    "\n",
    "# Saving only the model weights (state_dict)\n",
    "torch.save(geneformer_fine_tune.state_dict(), './fine_tuned_geneformer.pth')\n",
    "\n",
    "# Saving the model configuration\n",
    "import pickle\n",
    "with open('./fine_tuned_geneformer_config.pkl', 'wb') as f:\n",
    "    pickle.dump(geneformer_config, f)\n",
    "\n",
    "# Or Saving the full model (architecture + weights)\n",
    "torch.save(geneformer_fine_tune, './full_geneformer_model.pth')\n",
    "\n",
    "# Loading the full model (architecture + weights)\n",
    "loaded_model = torch.load('./full_geneformer_model.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baee9a00-b35e-4779-a07a-c3401bb5938b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the fine-tuned model to a specified directory\n",
    "\n",
    "# Save the model's state_dict (weights)\n",
    "torch.save(geneformer_fine_tune.state_dict(), './fine_tuned_geneformer.pth')\n",
    "\n",
    "import pickle\n",
    "\n",
    "# Save the configuration (such as model architecture, hyperparameters)\n",
    "with open('./fine_tuned_geneformer_config.pkl', 'wb') as f:\n",
    "    pickle.dump(geneformer_config, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e2795a-b5d5-444f-ba9c-53f3824a39b0",
   "metadata": {},
   "source": [
    "* Outputs: These are typically the logits from the final classification layer of the model.\n",
    "\n",
    "shape = number of cells x number of classes\n",
    "\n",
    "Embeddings: These are dense vector representations of the input\n",
    "shape = number of cells x number of dimensions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dced79e8-c656-4432-84d0-0551eba1ef29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get logits from the fine-tuned model\n",
    "outputs = geneformer_fine_tune.get_outputs(dataset)\n",
    "#print(outputs[:100])\n",
    "\n",
    "# Get embeddings from the fine-tuned model\n",
    "embeddings = geneformer_fine_tune.get_embeddings(dataset)\n",
    "#print(embeddings[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb368d4d-0e91-4496-affb-03930616d0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print dimensions of model outputs (logits)\n",
    "print(\"Outputs shape:\", outputs.shape)\n",
    "\n",
    "# Print dimensions of embeddings\n",
    "print(\"Embeddings shape:\", embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03238297-13e9-4c8e-a0b9-be43ee3c5d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model configuration\n",
    "with open('./fine_tuned_geneformer_config.pkl', 'rb') as f:\n",
    "    loaded_config = pickle.load(f)\n",
    "\n",
    "# Recreate the model using the configuration\n",
    "geneformer_fine_tune = GeneformerFineTuningModel(geneformer_config=loaded_config, fine_tuning_head=\"classification\", output_size=len(label_set))\n",
    "\n",
    "# Load the saved weights\n",
    "geneformer_fine_tune.load_state_dict(torch.load('./fine_tuned_geneformer.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96bba31b-c301-4c44-84bc-2f25738b07dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "ann_data = ad.read_h5ad(\"../yolksac_human.h5ad\")\n",
    "\n",
    "# Get the column for fine-tuning\n",
    "cell_types = list(ann_data.obs[\"LVL1\"][:10])\n",
    "label_set = set(cell_types)\n",
    "label_set\n",
    "# Process the data\n",
    "dataset = geneformer_fine_tune.process_data(ann_data[:10])\n",
    "\n",
    "dataset = dataset.add_column('cell_types', cell_types)\n",
    "\n",
    "# Create a dictionary to map cell types to ids\n",
    "class_id_dict = dict(zip(label_set, [i for i in range(len(label_set))]))\n",
    "\n",
    "def classes_to_ids(example):\n",
    "    example[\"cell_types\"] = class_id_dict[example[\"cell_types\"]]\n",
    "    return example\n",
    "\n",
    "# Convert cell types to ids\n",
    "dataset = dataset.map(classes_to_ids, num_proc=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f452b39-02b6-4c5a-b5b0-10f78173a0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get logits from the fine-tuned model\n",
    "outputs = geneformer_fine_tune.get_outputs(dataset)\n",
    "print(outputs[:10])\n",
    "\n",
    "# Get embeddings from the fine-tuned model\n",
    "embeddings = geneformer_fine_tune.get_embeddings(dataset)\n",
    "print(embeddings[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f718b88b-4606-4e89-89aa-4e69705fd5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Convert logits to probabilities using softmax\n",
    "probs = torch.nn.functional.softmax(torch.tensor(outputs), dim=-1)\n",
    "print(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a4b939-5b0d-4dae-92b6-a76c70989605",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predicted class (the class with the highest probability)\n",
    "predicted_classes = probs.argmax(dim=-1).numpy()  # Convert to numpy for easier handling\n",
    "print(predicted_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a9b469-8973-450b-9908-f6da9f8a1f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# True labels (cell types from dataset)\n",
    "true_labels = np.array(dataset[\"cell_types\"])\n",
    "print(true_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aadcf1c-3b57-4a7d-b3e2-cca395e2917f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare predicted labels with true labels to calculate accuracy\n",
    "accuracy = (predicted_classes == true_labels).mean()\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172cc62d-7066-4cac-9ed0-bab80835cba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
